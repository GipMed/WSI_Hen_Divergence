import os
from argparse import ArgumentParser

import torch
from pytorch_lightning import seed_everything
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import LearningRateMonitor
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint
from pytorch_lightning.loggers.tensorboard import TensorBoardLogger
from pytorch_lightning.loggers.wandb import WandbLogger
from torchvision.transforms.functional import to_pil_image
from torchvision.utils import make_grid

from datamodules import WsiDataModule
from wsi_classifier import WsiClassifier

WANDB_USER = "USER"
WANDB_PROJECT = "PROJECT"


def cli_main():
    parser = ArgumentParser()
    # program args
    parser.add_argument('--seed',
                        type=int,
                        default=None,
                        help='Seed for reproduceable training')
    parser.add_argument(
        '--ckpt_path',
        default=None,
        help='path of lightning checkpoint to resume training, \
                              provide: "wandb:<run_id>:<version>" to download and use a wandb checkpoint\
                              <version> can be a version number (ex: "v2") or an alias ("last" or "best")'
    )

    parser.add_argument(
        '--test',
        action='store_true',
        help='only run testing of model specified by ckpt_path')
    parser.add_argument(
        '--patience',
        type=int,
        default=0,
        help='Early stopping patience in epochs, set as 0 for no early stopping'
    )
    parser.add_argument(
        '--exp_name',
        type=str,
        default=None,
        help='Display name for wandb experiment, default is generated by wandb'
    )
    parser.add_argument('--no_wandb',
                        action='store_true',
                        help='Use tensorboard for logging instead of wandb')

    # debug, profiling, and testing args
    parser.add_argument(
        '--auto_find_batch_size',
        action="store_true",
        help=
        'debug: automatically find largest batch size that fits in memory and exit'
    )
    parser.add_argument(
        '--visualize_batch',
        action="store_true",
        help='debug: visualize a single training batch and exit')
    parser.add_argument('--log_parameters',
                        action="store_true",
                        help='log model parameters and gradients to wandb')
    parser.add_argument('--profile',
                        action='store_true',
                        help='debug: profile training')
    parser.add_argument(
        '--log_parameters',
        action="store_true",
        help='debug: log model parameters and gradients to wandb')

    # trainer args
    parser = Trainer.add_argparse_args(parser)
    # model args
    parser = WsiClassifier.add_model_specific_args(parser)
    # dataset args
    parser = WsiDataModule.add_argparse_args(parser)

    args = parser.parse_args()

    if args.seed is not None:
        seed_everything(args.seed, workers=True)
        # Ensure that all operations are deterministic on GPU (if used) for reproducibility
        torch.backends.cudnn.determinstic = True
        torch.backends.cudnn.benchmark = False

    # init datamodule
    dm = WsiDataModule(**args.__dict__)

    # TODO: this is neat and can be used for some debugging, possibly extract to utils function
    # if args.visualize_batch:
    #     dm.setup()
    #     imgs, _ = next(iter(dm.train_dataloader()))
    #     to_pil_image(make_grid(imgs)).show()
    #     return

    # init model
    model = WsiClassifier(**args.__dict__)

    # logger
    if args.wandb:
        logger = WandbLogger(
            project=WANDB_PROJECT,  # TODO: wandb project and configuration
            name=args.exp_name,
            log_model=True)
        if args.log_parameters:
            logger.watch(model, log="all", log_freq=500, log_graph=False)
    else:  # TODO: support tensorboard as alternative to wandb
        logger = TensorBoardLogger(save_dir='lightning_logs',
                                   name='-'.join([
                                       args.dataset, args.target,
                                       f'fold{args.val_fold}',
                                       args.logdir_postfix
                                   ]))

    # callbacks
    checkpoint_callback = ModelCheckpoint(
        monitor='val/auc',
        dirpath=(os.path.join('./checkpoints/wandb', logger.experiment.id)
                 if args.wandb else None),
        filename='epoch={epoch}-val_auc={val/auc:.3f}',
        auto_insert_metric_name=False,
        save_top_k=3,
        mode='max',
        save_last=True)
    early_stopping_callback = EarlyStopping(monitor='val/auc',
                                            patience=args.patience,
                                            mode='max')
    lr_monitor = LearningRateMonitor()
    callbacks = [checkpoint_callback, lr_monitor]
    if args.patience > 0:
        callbacks.append(early_stopping_callback)

    # init trainer
    trainer = Trainer.from_argparse_args(
        args,
        accelerator='gpu' if torch.cuda.is_available() else 'cpu',
        devices='auto',
        logger=logger,
        max_epochs=100 if args.max_epochs is None else args.max_epochs,
        auto_scale_batch_size=args.auto_find_batch_size,
        callbacks=callbacks)

    # find batch size
    if args.auto_find_batch_size:
        trainer.tune(model, datamodule=dm)
        return

    ckpt_path = args.ckpt_path
    if ckpt_path is not None and ckpt_path.startswith('wandb'):
        run_id, run_version = args.ckpt_path.split(':')[1:]
        checkpoint_reference = f"{WANDB_USER}/{WANDB_PROJECT}/{run_id}:{run_version}"
        # download checkpoint locally (if not already cached)
        if args.no_wandb:
            ckpt_path = WandbLogger.download_artifact(
                artifact=checkpoint_reference, artifact_type='model')
        else:
            ckpt_path = logger.download_artifact(artifact=checkpoint_reference,
                                                 artifact_type='model')

    # train
    trainer.fit(model, datamodule=dm, ckpt_path=args.ckpt_path)

    # TODO: test for metrics of best model on validation set, could be used to save results
    # trainer.test(ckpt_path='best', datamodule=dm)


if __name__ == "__main__":
    cli_main()
